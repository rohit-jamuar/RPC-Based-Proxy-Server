#Analysis

###From graphs obtained for cache hits:
MAXS replacement policy produced the most efficient proxy server. There is plausibility to this as MAXS always removes contents in a non-increasing manner, hence always ensuring that maximum room is left for newer fetches (to acquire). Until the number of requests are not biased towards URLs with comparatively large HTML body, MAXS is bound to do well for the mentioned reason. Needless to pontificate, but size of cache improves hit ratio substantially - by doubling the cache size, the hit ratios (almost) doubled themselves! The most disappointing policy (among the three) was FIFO. Considering the fact that FIFO pays no heed to cache warmth, if the workload constitutes a repetition of same set of URLs (Workload-A), the performance is abysmal. If the workload is skewed (like Workload-B), FIFO does salvage itself - but not to the same capacity as other two policies. We anticipated RAND policy to do somewhere between the two extremes, and we were right about our conjecture for most parts. The only deviation of RAND’s behavior is in case of Workload-B (with cache size = 256KB) - it performed the worst in its group. This behavior is attributed to the randomized nature of this algorithm, coupled with the random placement of URLs across the workload.

###From graphs derived using average serving times:
The workload type and cache size had direct impact on average times. For Workload-A, FIFO took more time irrespective of cache size. Analyzing this behavior further, this behavior was attributed to FIFO’s disregard of cache warmth. As Workload-A had the same set of URLs, the eviction policy forced them out in a FIFO manner, which then had to be re-fetched into cache due to ordering of requests - hence an increase in the average latency. Therefore, FIFO will not be the right caching policy to implement for repetitive workloads. For Workload-B, FIFO performs relatively better and matches the performance of RAND and MAXS schemes (for cache with size 256 KB). This behavior looks like an aftermath of random distribution of URLs in workload. The RAND’s performance was rather surprising with respect to growth in cache size - didn’t expect to see RAND to be the most performant. This behavior could be due to random nature of this scheme, coupled with a larger cache. The MAXS caching strategy works really well on all workloads and cache sizes. With repetitive workloads (like Workload-A), it gives the best performance (despite smaller cache size) - this is because it removes contents from the cache based on their size; when a larger data entry is removed, more space is made for smaller payloads and hence cache hit increases. This reduces the overall latency for MAXS (for Workload-A). For skewed workloads (like Workload-B), the MAXS perform well, but is given a stiff competition by RAND - i.e. in case of larger cache sizes. MAXS is relatively less performant for repetitive workloads (like Workload-A) on bigger caches because in each iteration over the set of URLs, the larger contents are removed, hence, each such iteration forces the cache to re-fetch hefty contents of evicted URLs. This leads to increased latency for MAXS as compared to RAND and FIFO. 
